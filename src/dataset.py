import os
import torch
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
from PIL import Image


class MaskDataset(Dataset):
    def __init__(self, data_dir, transform=None):
        self.data_dir = data_dir
        self.transform = transform
        self.images = []
        self.labels = []
        
        # ë°ì´í„° ë¡œë“œ
        self._load_data()
    
    def _load_data(self):
        """ë°ì´í„° íŒŒì¼ ê²½ë¡œì™€ ë¼ë²¨ ìƒì„±"""
        classes = ['with_mask', 'without_mask']
        
        for class_idx, class_name in enumerate(classes):
            class_path = os.path.join(self.data_dir, class_name)
            if os.path.exists(class_path):
                for img_name in os.listdir(class_path):
                    if img_name.lower().endswith(('.jpg', '.jpeg', '.png')):
                        img_path = os.path.join(class_path, img_name)
                        self.images.append(img_path)
                        self.labels.append(class_idx)
        
        print(f"ğŸ“Š ì´ ë°ì´í„° ìˆ˜: {len(self.images)}ê°œ")
        print(f"   - with_mask: {self.labels.count(0)}ê°œ")
        print(f"   - without_mask: {self.labels.count(1)}ê°œ")
    
    def __len__(self):
        return len(self.images)
    
    def __getitem__(self, idx):
        img_path = self.images[idx]
        label = self.labels[idx]
        
        # ì´ë¯¸ì§€ ë¡œë“œ
        try:
            image = Image.open(img_path).convert('RGB')
        except Exception as e:
            print(f"âŒ ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {img_path}")
            # ê¸°ë³¸ ì´ë¯¸ì§€ ìƒì„± (ì—ëŸ¬ ë°©ì§€)
            image = Image.new('RGB', (224, 224), color='white')
        
        if self.transform:
            image = self.transform(image)
        
        return image, label


def get_transforms():
    """ë°ì´í„° ì „ì²˜ë¦¬ ë³€í™˜ ì •ì˜"""
    # í•™ìŠµìš© (ê°„ë‹¨í•œ ë°ì´í„° ì¦ê°•)
    train_transform = transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.RandomHorizontalFlip(p=0.5),  # ì¢Œìš° ë°˜ì „
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])
    
    # ê²€ì¦/í…ŒìŠ¤íŠ¸ìš© (ì¦ê°• ì—†ìŒ)
    val_transform = transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])
    
    return train_transform, val_transform


def get_dataloaders(data_dir, batch_size=16, train_split=0.8):
    """ë°ì´í„°ë¡œë” ìƒì„±"""
    train_transform, val_transform = get_transforms()
    
    # ì „ì²´ ë°ì´í„°ì…‹ ë¡œë“œ
    full_dataset = MaskDataset(data_dir, transform=train_transform)
    
    # í›ˆë ¨/ê²€ì¦ ë¶„í• 
    train_size = int(train_split * len(full_dataset))
    val_size = len(full_dataset) - train_size
    
    train_dataset, val_dataset = torch.utils.data.random_split(
        full_dataset, [train_size, val_size]
    )
    
    # ê²€ì¦ ë°ì´í„°ëŠ” ë‹¤ë¥¸ ë³€í™˜ ì ìš©
    val_dataset.dataset.transform = val_transform
    
    # ë°ì´í„°ë¡œë” ìƒì„±
    train_loader = DataLoader(
        train_dataset, 
        batch_size=batch_size, 
        shuffle=True, 
        num_workers=0  # Windows í˜¸í™˜ì„±
    )
    
    val_loader = DataLoader(
        val_dataset, 
        batch_size=batch_size, 
        shuffle=False, 
        num_workers=0
    )
    
    print(f"ğŸ“š í›ˆë ¨ ë°ì´í„°: {len(train_dataset)}ê°œ")
    print(f"ğŸ“š ê²€ì¦ ë°ì´í„°: {len(val_dataset)}ê°œ")
    
    return train_loader, val_loader


if __name__ == "__main__":
    # ë°ì´í„°ì…‹ í…ŒìŠ¤íŠ¸
    data_dir = "data"
    if os.path.exists(data_dir):
        train_loader, val_loader = get_dataloaders(data_dir, batch_size=8)
        print("âœ… ë°ì´í„°ë¡œë” ìƒì„± ì™„ë£Œ!")
    else:
        print("âŒ data í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
